{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Lab Client <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates you how to connect to a Lab instance, manage data and run your experiments.\n",
    "\n",
    "**In this notebook:**\n",
    "\n",
    "* [Initialize environment from ML Lab](#Initialize-Environment)\n",
    "* [Create an experiment and store result data](#Create-Experiment)\n",
    "* [Load & upload data from/to remote storage](#Load-files-from-remote-storage)\n",
    "* [Run an experiment, track & share experiment metadata](#Create-and-Run-Experiment) \n",
    "* [Create and upload unified model](#Create-Unified-Model)\n",
    "* [Access Lab functionality via the Lab API](#Access-Lab-Functionality-via-the-Lab-API)\n",
    "\n",
    "_The library and this notebook is currently only tested with Python 3._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "In the first step, we will just install and import all dependencies required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:06:58.704190Z",
     "start_time": "2020-08-19T13:06:57.386751Z"
    }
   },
   "outputs": [],
   "source": [
    "# System libraries\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Lab libraries\n",
    "from lab_client import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment\n",
    "The **environment** provides functionality to manage all project-related files (e.g. models & datasets) and experiments. A **project** is a digital space for tackling a specific data science use-case that consists of multiple datasets, experiments, models, services, and jobs.\n",
    "\n",
    "The environment can be connected to an Lab instance by providing the `lab_endpoint` and a valid `lab_api_token`. If connected, the environment provides easy access to the Lab API and capabilities to download/upload data, and sync experiments. Locally, the environment has a [dedicated folder](../environment) structure to save and load datasets, models, and experiment data which can be configured via the `DATA_ENVIRONMENT` environment variable or provided via `root_path` param during initialization.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "To run this code you need to have created a project within the Lab instance and replace LAB_PROJECT with your project!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:01.961855Z",
     "start_time": "2020-08-19T13:07:01.488741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env = Environment(project=\"LAB_PROJECT\",  # Lab project you want to work on\n",
    "                  # Only required in stand-alone workspace deployments \n",
    "                  # lab_endpoint=\"LAB_ENDPOINT\", \n",
    "                  # lab_api_token=\"LAB_TOKEN\" \n",
    "                 )\n",
    "\n",
    "# Show environment information\n",
    "env.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Experiment\n",
    "An **experiment** is a single execution of a data science code with specific parameters, data, and results. An experiment in the data science field usually refers to a single model training run, but can also be any other computational task, such as a data transformation, that requires a certain configuration and has some measurable results. \n",
    "\n",
    "You can initialize a new experiment with a given name from the environment via `create_experiment`. The `Experiment` instance manages all metadata and resources such as parameters, timestamps, input & output files, resulting metrics (e.g. accuracy), and other related information. The experiment metadata is automatically synced to the connected Lab instance to enable reproducibility, transparency, and collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:04.481034Z",
     "start_time": "2020-08-19T13:07:04.035902Z"
    }
   },
   "outputs": [],
   "source": [
    "exp = env.create_experiment('Environment Tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-17T14:01:44.917721Z",
     "start_time": "2018-11-17T14:01:44.897472Z"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We recommend to initialize one <i>Experiment</i> instance per notebook or script. For tasks such as hyper-parameter optimization, you can also create multiple <i>Experiment</i> instances.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store information within the experiment folder\n",
    "Every experiment has its own unique folder within the environment that should be used to store all data related to the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:06.713506Z",
     "start_time": "2020-08-19T13:07:06.706242Z"
    }
   },
   "outputs": [],
   "source": [
    "print(exp.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `create_file_path` on the `Experiment` instance to get the correct path to the experiment folder for a given filename. Additionally, the file will also be tracked as artifact in the experiment metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:07.618969Z",
     "start_time": "2020-08-19T13:07:07.612064Z"
    }
   },
   "outputs": [],
   "source": [
    "new_file_path = exp.create_file_path(\"test.txt\")\n",
    "\n",
    "# Create test.txt file in experiment folder\n",
    "with open(new_file_path, \"w\") as text_file:\n",
    "    text_file.write(\"test content\")\n",
    "print(\"Created new file in experiment folder: \" + new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a demonstration on how to use the experiment instance to save data. We will later use the same functionality in the model training to save the trained model file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T21:23:17.284995Z",
     "start_time": "2017-07-25T21:23:17.257974Z"
    }
   },
   "source": [
    "# Load files from remote storage\n",
    "Use the `get_file` method to request a file (e.g. dataset or model) either from the local directory or the remote storage from the connected Lab. This method will return the full path to the specified file if it exists. If the file does not exist locally, it will be automatically downloaded (cached) from the remote storage into the project folder. Since the remote storage supports versioning of files, you will always get the newest version from remote storage. You can also directly load a specific version by attaching the `.v` suffix to the key (e.g. `.v2` for the second version of the file).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "A <b>dataset</b> is a single file that contains raw- or processed-data, usually preselected for a certain experiment. It is recommended to have the dataset in an easily readable format such as CSV for structured data or GraphML for graph data. If your dataset consists of multiple files (e.g. collection of images), we recommend packaging this dataset to a single file.\n",
    "</div>\n",
    "\n",
    "For this tutorial, we have prepared a dataset that contains about 5k news articles categorized into topics. Our goal is to train a classification model that is able to predict the topic of a news article. You can download the dataset [**here**](/docs/walkthrough/data/download-dataset.html). Please upload this dataset within you project on Lab, copy the key to clipboard, and insert it into the `get_file` function below.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "To run this code you need to have uploaded the dataset to the Lab instance!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:45.260499Z",
     "start_time": "2020-08-19T13:07:45.182753Z"
    }
   },
   "outputs": [],
   "source": [
    "# tutorial file -> datasets/news-categorized.csv (needs to be uploaded)\n",
    "text_corpus_path = env.get_file('datasets/news-categorized.csv')\n",
    "print(\"Remote file saved to: \" + text_corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the downloaded file into a dataframe and split it for model training by using default pandas and numpy functionalities. For more information about pandas or numpy, please refer to the [pandas-tutorial](./pandas-tutorial.ipynb) and [numpy-tutorial](./numpy-tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:48.910319Z",
     "start_time": "2020-08-19T13:07:48.046760Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset via pandas\n",
    "df = pd.read_csv(text_corpus_path, sep=\";\")\n",
    "\n",
    "# only use items with more than 15 labels\n",
    "df = df.groupby(\"label\").filter(lambda x: len(x) > 15)\n",
    "\n",
    "# Split this dataset into train (80%), and test (20%)\n",
    "train_df, test_df = np.split(df.sample(frac=1, random_state=1), [int(.8*len(df))])\n",
    "\n",
    "# add dataframes to experiment (will be logged and accesible within the experiment)\n",
    "exp.add_artifact(\"train_data\", train_df)\n",
    "exp.add_artifact(\"test_data\", test_df)\n",
    "\n",
    "# Show sample\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `env.get_file` method to load files from an URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:57.820614Z",
     "start_time": "2020-08-19T13:07:49.665715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get file from URL\n",
    "env.get_file('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run Experiment \n",
    "Use the `run_exp` method of the experiment instance to execute your experiment. This method takes in a function that contains your actual experiment logic (code) and a python dictionary that holds your experiment parameters (configuration). All experiment metadata are automatically synchronized with the Lab Instance on an on-going basis during the experiment run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Experiment\n",
    "Before we can run the experiment, we have to define our experiment code in the `train` function (you can name this function however you like):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:07:59.973557Z",
     "start_time": "2020-08-19T13:07:57.825543Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Define a function with the required code to run the experiment (e.g. train model)\n",
    "def train(exp, params, artifacts):\n",
    "    # exp (= Experiment instance)\n",
    "    # params (= parameter dictonary) \n",
    "    # artifacts (= dictionary of added artifacts)\n",
    "    # these variables are automatically provided (but not required)\n",
    "    \n",
    "    # Get artifacts for the experiment run\n",
    "    train_df = artifacts[\"train_data\"]\n",
    "    test_df = artifacts[\"test_data\"]\n",
    "    \n",
    "    # Experiment Implementation\n",
    "    classification_pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(analyzer=lambda x: x,min_df=params['min_df'])),\n",
    "        (\"lsvc_calib\", CalibratedClassifierCV(LinearSVC(verbose=0),method=\"isotonic\", cv=3))\n",
    "    ])\n",
    "    \n",
    "    sklearn_classifier = classification_pipeline.fit(\n",
    "        [str(item).split() for item in train_df[\"text\"].tolist()], train_df[\"label\"].tolist()\n",
    "    )\n",
    "    \n",
    "    # Add trained model instance to experiment -> it can accessed after the exp-run is finished\n",
    "    exp.add_artifact(\"sklearn_classifier\", sklearn_classifier)\n",
    "    \n",
    "    # Evaluate trained model\n",
    "    score = sklearn_classifier.score(\n",
    "        [str(item).split() for item in test_df[\"text\"].tolist()], test_df[\"label\"].tolist()\n",
    "    )\n",
    "    \n",
    "    # log a metric to the current experiment\n",
    "    exp.log_metric(\"accuracy\", score)\n",
    "    \n",
    "    # optional: return the most descriptive metric (main objective) for the experiment\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment\n",
    "Run the experiment with a defined set of parameters via the `run_exp` function of the `Experiment` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:06.105677Z",
     "start_time": "2020-08-19T13:07:59.976898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define parameter configuration for experiment run\n",
    "params = {\n",
    "    'min_df': 2 # value should be string, int or float\n",
    "}\n",
    "\n",
    "# Run experiment and automatically sync all metadata\n",
    "exp.run_exp(train, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment execution automatically records a variety of information and also allows you to manually log information, such as:\n",
    "\n",
    "- Parameters: Key-value input parameters (hyperparameter) for the experiment\n",
    "- Metrics: Key-value result metrics for the experiment\n",
    "- Start-/Finish-time, duration, and current status\n",
    "- Host Information: CPU, GPUs, hostname, os, python version...\n",
    "- Dependencies: pip-installable dependencies with versions required for the experiment\n",
    "- Git Information: repo url, commit hash, branch, user\n",
    "- Resources: Input & output files (stored in Lab project), source-code,  and stdout logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:06.124672Z",
     "start_time": "2020-08-19T13:08:06.111268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print experiment information\n",
    "exp.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the experimentation process, one or more parameters are changed by the data scientist in an organized manner, and the effects of these changes on associated metrics are measured, recorded, and analyzed. Data scientist may try many different approaches, different parameters  and fail many times before the required level of a metric is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Unified Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **model** is an artifact that is created in the training process. A model is something that predicts an output for a given input. Any file created after training from an ML algorithm is a model. The model needs to be deployed as a service in order to offer the model's prediction capabilities for integration into applications.\n",
    "\n",
    "In order to easily share and deploy the trained model, we will use the [unified model library](#TODO) to create a self-contained executable model file. You can find more information about this library [here](#TODO) and in the [unified-model tutorial](./unified-model-tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:10.541482Z",
     "start_time": "2020-08-19T13:08:06.129294Z"
    }
   },
   "outputs": [],
   "source": [
    "from unified_model.predefined_models.sklearn_models import SklearnTextClassifier\n",
    "\n",
    "# Optional: create a describable name for the model\n",
    "model_name = \"news-categorized_sklearn_classifier.model\"\n",
    "\n",
    "# Initialize model instance with trained model\n",
    "unified_model = SklearnTextClassifier(\n",
    "    sklearn_classifier=exp.get_artifact(\"sklearn_classifier\"), \n",
    "    name=model_name)\n",
    "\n",
    "# Save the unified model within the dedicated experiment folder\n",
    "model_path = exp.create_file_path(model_name)\n",
    "# Save unified model\n",
    "unified_model_path = unified_model.save(model_path)\n",
    "\n",
    "# Test prediction functionality\n",
    "unified_model.predict(\"mobile apps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to remote storage\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a file\n",
    "Use `upload_file` to upload the trained model to the remote storage. This is the best way to release finished models or share data for usage on other machines and for other developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:13.807697Z",
     "start_time": "2020-08-19T13:08:10.547179Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uploaded_model_key = env.upload_file(unified_model_path, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a folder\n",
    "Use `upload_folder` to upload a folder to the remote storage. The folder will be automatically zipped before it is uploaded as an archive file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:16.009218Z",
     "start_time": "2020-08-19T13:08:13.812389Z"
    }
   },
   "outputs": [],
   "source": [
    "zipped_folder_key = env.upload_folder(exp.output_path, \"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a folder from the remote storage\n",
    "Use `get_file` with the `unpack=True` option to download the archive file and automatically unpack it. This method directly returns the path to the folder. A variety of compression formats are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:16.737864Z",
     "start_time": "2020-08-19T13:08:16.014679Z"
    }
   },
   "outputs": [],
   "source": [
    "env.get_file(zipped_folder_key, unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T20:56:54.778171Z",
     "start_time": "2018-02-23T20:56:54.738128Z"
    }
   },
   "source": [
    "# Access Lab Functionality via the Lab API\n",
    "The ML Lab provides a REST API to access information and functionality. An API documentation is available under this URL: `<LAB_ENDPOINT>/api`. There is also an API client available within the environment as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:24.835491Z",
     "start_time": "2020-08-19T13:08:16.751132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy unified model as service\n",
    "env.lab_handler.lab_api.deploy_model(project=env.project, file_key=uploaded_model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have deployed the uploaded model via the Lab API as a service. In your Lab Instance, go to `Services` and click `Access` on the deployed model service to access the API Explorer of the Unified Model Service.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "A <b>service</b> is a software component that implements and provides specific capabilities. In our landscape, services are deployed as Docker containers and are usually accessible via a REST API over HTTP(S).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Lab Client via CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:27.446298Z",
     "start_time": "2020-08-19T13:08:24.845037Z"
    }
   },
   "outputs": [],
   "source": [
    "!lab --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T13:08:49.620029Z",
     "start_time": "2020-08-19T13:08:46.940860Z"
    }
   },
   "outputs": [],
   "source": [
    "!lab get-file datasets/news-categorized.csv --project=$env.project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T03:15:06.487548Z",
     "start_time": "2018-03-09T03:15:06.477842Z"
    }
   },
   "source": [
    "- [Lab Walkthrough](/docs/walkthrough/lab-walkthrough/): A step-by-step tutorial from project-creation to model-deployment.\n",
    "- [Unified Model Tutorial](./unified-model-tutorial.ipynb): Package your model logic, requirements, and artifacts into a single self-contained & executable file. \n",
    "- [Jupyter Tipps & Tricks](./jupyter-tipps.ipynb): Explore some amazing functionalities that you can use with Jupyter within the workspace.\n",
    "- [Experiment Template](../templates/experiment-template.ipynb): Start your own high-quality reusable experiment notebook with this template."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
